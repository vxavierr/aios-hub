# Story CL2-041: Evolution Log System

**Story ID:** CL2-041
**Epic:** EPIC-CLONE-LAB-V2
**Phase:** 3 - Meta-Cognition
**Status:** Ready
**Points:** 5
**Author:** Morgan (PM)

---

## Description

Implementar o **Evolution Log System** - sistema de log centralizado que registra todas as mudanças, decisões, rollbacks e avaliações de impacto do sistema de meta-cognição.

### Problem Statement
O Clone Lab precisa de um registro completo e auditável de todas as atividades de auto-modificação. O Evolution Log fornece rastreabilidade completa para debugging, auditoria e aprendizado.

---

## Acceptance Criteria

```gherkin
Given a change is applied
When the log is queried
Then the complete change record is available

Given multiple log entries exist
When filtering by type or date
Then relevant entries are returned efficiently

Given the log grows large
When retention is applied
Then old entries are archived while maintaining searchability

Given an audit is required
When the log is exported
Then a complete audit trail is available
```

---

## Technical Requirements

### Evolution Log

```typescript
// packages/meta/src/evolution/log.ts

export type LogEntryType =
  | 'change_applied'
  | 'change_rejected'
  | 'rollback'
  | 'impact_measured'
  | 'assessment_completed'
  | 'recommendation_generated'
  | 'pattern_learned'
  | 'constitution_check';

export interface LogEntry {
  id: string;
  type: LogEntryType;
  timestamp: Date;
  data: Record<string, unknown>;
  metadata: LogMetadata;
}

export interface LogMetadata {
  changeId?: string;
  component: string;
  triggeredBy: 'auto' | 'human' | 'scheduled';
  sessionId?: string;
  correlationId?: string;
}

export interface LogQuery {
  types?: LogEntryType[];
  startDate?: Date;
  endDate?: Date;
  changeId?: string;
  component?: string;
  triggeredBy?: 'auto' | 'human' | 'scheduled';
  limit?: number;
  offset?: number;
}

export class EvolutionLog {
  private readonly storage: LogStorage;
  private readonly indexer: LogIndexer;

  constructor(storage: LogStorage, indexer: LogIndexer) {
    this.storage = storage;
    this.indexer = indexer;
  }

  async log(entry: Omit<LogEntry, 'id' | 'timestamp'>): Promise<LogEntry> {
    const fullEntry: LogEntry = {
      id: generateId(),
      timestamp: new Date(),
      ...entry
    };

    // Store the entry
    await this.storage.append(fullEntry);

    // Update indexes
    await this.indexer.index(fullEntry);

    return fullEntry;
  }

  async logChange(change: AppliedChange): Promise<LogEntry> {
    return this.log({
      type: 'change_applied',
      data: {
        changeId: change.id,
        improvement: change.improvement,
        appliedBy: change.appliedBy,
        beforeState: change.beforeState,
        afterState: change.afterState,
        status: change.status
      },
      metadata: {
        changeId: change.id,
        component: 'change-applier',
        triggeredBy: change.appliedBy === 'auto' ? 'auto' : 'human'
      }
    });
  }

  async logRollback(params: {
    rollbackId: string;
    originalChangeId: string;
    result: RollbackResult;
    timestamp: Date;
  }): Promise<LogEntry> {
    return this.log({
      type: 'rollback',
      data: {
        rollbackId: params.rollbackId,
        originalChangeId: params.originalChangeId,
        status: params.result.status,
        restoredFiles: params.result.restoredFiles
      },
      metadata: {
        changeId: params.originalChangeId,
        component: 'rollback-manager',
        triggeredBy: params.result.request.triggeredBy
      }
    });
  }

  async logImpact(params: {
    resultId: string;
    changeId: string;
    impact: ImpactAssessment;
    timestamp: Date;
  }): Promise<LogEntry> {
    return this.log({
      type: 'impact_measured',
      data: {
        resultId: params.resultId,
        changeId: params.changeId,
        overallScore: params.impact.overallScore,
        verdict: params.impact.verdict,
        recommendation: params.impact.recommendation,
        metrics: params.impact.metrics
      },
      metadata: {
        changeId: params.changeId,
        component: 'result-tracker',
        triggeredBy: 'auto'
      }
    });
  }

  async query(query: LogQuery): Promise<LogEntry[]> {
    // Use indexes for efficient querying
    const indexResults = await this.indexer.search(query);

    // Fetch full entries
    const entries = await Promise.all(
      indexResults.map(id => this.storage.get(id))
    );

    return entries.filter(Boolean) as LogEntry[];
  }

  async getChange(changeId: string): Promise<LogEntry | null> {
    const entries = await this.query({ changeId, types: ['change_applied'] });
    return entries[0] || null;
  }

  async getChangesAfter(changeId: string): Promise<LogEntry[]> {
    const reference = await this.getChange(changeId);
    if (!reference) return [];

    return this.query({
      types: ['change_applied'],
      startDate: reference.timestamp
    });
  }

  async getChangeHistory(changeId: string): Promise<LogEntry[]> {
    return this.query({
      changeId,
      limit: 100
    });
  }

  async export(options: ExportOptions): Promise<LogExport> {
    const entries = await this.query({
      startDate: options.startDate,
      endDate: options.endDate,
      limit: options.limit || 10000
    });

    return {
      exportedAt: new Date(),
      totalEntries: entries.length,
      entries,
      format: options.format || 'json'
    };
  }

  async getStatistics(): Promise<LogStatistics> {
    const allEntries = await this.query({ limit: 100000 });

    return {
      totalEntries: allEntries.length,
      byType: this.countByType(allEntries),
      byComponent: this.countByComponent(allEntries),
      byTrigger: this.countByTrigger(allEntries),
      oldestEntry: allEntries[allEntries.length - 1]?.timestamp,
      newestEntry: allEntries[0]?.timestamp
    };
  }

  private countByType(entries: LogEntry[]): Record<LogEntryType, number> {
    return entries.reduce((acc, entry) => {
      acc[entry.type] = (acc[entry.type] || 0) + 1;
      return acc;
    }, {} as Record<LogEntryType, number>);
  }

  private countByComponent(entries: LogEntry[]): Record<string, number> {
    return entries.reduce((acc, entry) => {
      const component = entry.metadata.component;
      acc[component] = (acc[component] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
  }

  private countByTrigger(entries: LogEntry[]): Record<string, number> {
    return entries.reduce((acc, entry) => {
      const trigger = entry.metadata.triggeredBy;
      acc[trigger] = (acc[trigger] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
  }
}
```

### Log Storage

```typescript
// packages/meta/src/evolution/storage.ts

export interface LogStorage {
  append(entry: LogEntry): Promise<void>;
  get(id: string): Promise<LogEntry | null>;
  query(criteria: StorageQuery): Promise<string[]>;  // Returns IDs
  delete(id: string): Promise<void>;
  archive(beforeDate: Date): Promise<number>;
}

export class FileLogStorage implements LogStorage {
  private readonly basePath: string;
  private readonly maxFileSize: number;
  private currentFile: string;
  private currentIndex: number;

  constructor(config: StorageConfig) {
    this.basePath = config.path;
    this.maxFileSize = config.maxFileSize || 10 * 1024 * 1024; // 10MB
    this.currentIndex = 0;
    this.currentFile = this.getLogFilePath(0);
  }

  async append(entry: LogEntry): Promise<void> {
    // Check if current file is too large
    if (await this.isFileTooLarge(this.currentFile)) {
      this.currentIndex++;
      this.currentFile = this.getLogFilePath(this.currentIndex);
    }

    // Append entry as JSON line
    const line = JSON.stringify(entry) + '\n';
    await fs.appendFile(this.currentFile, line);
  }

  async get(id: string): Promise<LogEntry | null> {
    // Search in index first
    const location = await this.findEntryLocation(id);
    if (!location) return null;

    // Read from file
    const content = await fs.readFile(location.file, 'utf-8');
    const lines = content.split('\n');

    for (const line of lines) {
      if (line.trim()) {
        const entry = JSON.parse(line) as LogEntry;
        if (entry.id === id) {
          return entry;
        }
      }
    }

    return null;
  }

  async archive(beforeDate: Date): Promise<number> {
    const files = await this.getLogFiles();
    let archivedCount = 0;

    for (const file of files) {
      const entries = await this.readFileEntries(file);
      const shouldArchive = entries.every(e => e.timestamp < beforeDate);

      if (shouldArchive) {
        const archivePath = this.getArchivePath(file);
        await fs.rename(file, archivePath);
        archivedCount++;
      }
    }

    return archivedCount;
  }

  private getLogFilePath(index: number): string {
    return path.join(this.basePath, `evolution-${index.toString().padStart(6, '0')}.log`);
  }

  private getArchivePath(file: string): string {
    const archiveDir = path.join(this.basePath, 'archive');
    return path.join(archiveDir, path.basename(file));
  }
}
```

### Log Indexer

```typescript
// packages/meta/src/evolution/indexer.ts

export class LogIndexer {
  private readonly indexes: Map<string, Index>;

  constructor() {
    // Create indexes for common query patterns
    this.indexes = new Map([
      ['type', new Index('type')],
      ['timestamp', new Index('timestamp')],
      ['changeId', new Index('metadata.changeId')],
      ['component', new Index('metadata.component')]
    ]);
  }

  async index(entry: LogEntry): Promise<void> {
    for (const [name, index] of this.indexes) {
      await index.add(entry);
    }
  }

  async search(query: LogQuery): Promise<string[]> {
    let resultIds: Set<string> | null = null;

    // Apply each filter
    if (query.types) {
      const typeIds = await this.searchByType(query.types);
      resultIds = this.intersect(resultIds, typeIds);
    }

    if (query.startDate || query.endDate) {
      const dateIds = await this.searchByDateRange(query.startDate, query.endDate);
      resultIds = this.intersect(resultIds, dateIds);
    }

    if (query.changeId) {
      const changeIds = await this.searchByChangeId(query.changeId);
      resultIds = this.intersect(resultIds, changeIds);
    }

    if (query.component) {
      const componentIds = await this.searchByComponent(query.component);
      resultIds = this.intersect(resultIds, componentIds);
    }

    // Apply pagination
    let ids = Array.from(resultIds || []);

    if (query.offset) {
      ids = ids.slice(query.offset);
    }

    if (query.limit) {
      ids = ids.slice(0, query.limit);
    }

    return ids;
  }

  private intersect(existing: Set<string> | null, newIds: Set<string>): Set<string> {
    if (!existing) return newIds;

    const result = new Set<string>();
    for (const id of existing) {
      if (newIds.has(id)) {
        result.add(id);
      }
    }
    return result;
  }
}
```

---

## Business Value

O Evolution Log System fornece **rastreabilidade completa** de todas as atividades de auto-modificação, essencial para auditoria, debugging e aprendizado.

**Benefícios:**
- Auditoria completa de mudanças
- Debugging de problemas
- Base para aprendizado do sistema
- Compliance e accountability

---

## Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Log grows unbounded | High | Medium | Archival + retention |
| Performance degradation | Medium | Low | Indexing |
| Data loss | Low | Critical | Replication |

---

## Scope

### In Scope
- EvolutionLog class
- File-based storage
- Indexing for efficient queries
- Export functionality
- Statistics

### Out of Scope
- Database storage
- Distributed logging
- Real-time streaming

---

## Dependencies

| Dependency | Type | Status |
|------------|------|--------|
| CL2-028 (Meta Package Setup) | Package | Pending |
| @clone-lab/core | Package | Available |

---

## Dev Notes

### Log File Format

```
# Each entry is a JSON line
{"id":"...","type":"change_applied","timestamp":"2026-02-20T...","data":{...},"metadata":{...}}
{"id":"...","type":"impact_measured","timestamp":"2026-02-20T...","data":{...},"metadata":{...}}
```

### Retention Policy

```yaml
retention:
  active: 30d        # Keep in active storage
  archive: 365d      # Keep in archive
  purge: after 365d  # Delete old entries
```

---

## File List

| File | Action | Status |
|------|--------|--------|
| `packages/meta/src/evolution/log.ts` | Create | Pending |
| `packages/meta/src/evolution/storage.ts` | Create | Pending |
| `packages/meta/src/evolution/indexer.ts` | Create | Pending |
| `packages/meta/src/evolution/types.ts` | Create | Pending |
| `packages/meta/src/evolution/index.ts` | Create | Pending |
| `packages/meta/src/evolution/__tests__/log.test.ts` | Create | Pending |

---

## Definition of Done

- [ ] Log entries recorded correctly
- [ ] Queries return correct results
- [ ] Indexing improves query performance
- [ ] Export works
- [ ] Statistics accurate
- [ ] Archival works
- [ ] Lint passa sem erros
- [ ] Code review aprovado

---

## QA Checklist

- [ ] Log entries recorded correctly
- [ ] Queries return correct results
- [ ] Indexing improves query performance
- [ ] Export works
- [ ] Statistics accurate
- [ ] Archival works
- [ ] All tests pass

---

## Change Log

| Date | Author | Description |
|------|--------|-------------|
| 2026-02-20 | Morgan (PM) | Story created |

---

*Story generated by Morgan (PM Agent) - AIOS Framework*
